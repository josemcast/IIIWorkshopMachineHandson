{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição do problema\n",
    "\n",
    "Usuários da eNB1 se afastam da mesma em linha reta e com um ângulo aleatório, enquanto realizam o download de um vídeo de 15 MB. Eventualmente, devido ao enfraquecimento do sinal da sua eNB, eles fazem handover para a eNB2 ou eNB3 através do algoritmo A3RSRP. Com acesso aos **sinais de referência** das 3 eNBs no momento do handover, use redes neurais para prever em qual **região** se encontra cada usuário e qual **vazão** possuem os mesmos nos primeiros 100 segundos de simulação.\n",
    "<img src=\"ang.png\" style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Parte 2 - Classificação\n",
    "<font color='blue'>Problemas de classificação são aqueles cujo desafio é prever o valor de uma variável dependente categórica, tal como a variável **region** deste dataset. Nesta etapa do HandsOn, você deverá criar uma rede neural usando as bibliotecas sklearn, keras e tensorflow para classificar corretamente esta variável.</font>\n",
    "\n",
    "Obs.: Antes de criar os classificadores, execute o código criado na parte 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando sklearn\n",
    "Além de fornecer todas as funções que utilizadas neste hands on para processamento dos dados, seleção de modelos e testes de desempenho, a biblioteca sklearn também permite a criação de redes neurais de forma simplificada, sendo necessário apenas instanciar objetos das classes **MLPClassifier** (classificação) e **MLPRegressor** (regressão) para fazê-lo. \n",
    "\n",
    "### Parâmetros importantes do <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">**MLPClassifier**</a> :\n",
    "* **hidden_layer_sizes** (número de neurônios nas camadas escondidas)\n",
    "* **solver** (algoritmo de otimização usado para o aprendizado)\n",
    "    * lbfgs\n",
    "        * *Limited-memory Broyden–Fletcher–Goldfarb–Shanno*.\n",
    "        * Método da família quase-Netwon.\n",
    "    * adam \n",
    "        * *Adaptive moment estimation*.\n",
    "        * Método estocástico de primeira ordem.\n",
    "        * <a href=\"https://arxiv.org/pdf/1412.6980.pdf\"> Descrição do método</a>.\n",
    "    * sgd \n",
    "        * *Stochastic gradient descent*.\n",
    "        * Método estocástico de primeira ordem.\n",
    "* **activation** (função de ativação para as camadas escondidas)\n",
    "    * relu \n",
    "        * $ f(x) = max(0,x) $\n",
    "    * tanh \n",
    "        * $ f(x) = tanh(x) $\n",
    "    * identity \n",
    "        * $ f(x) = x $\n",
    "    * logistic \n",
    "        * $ f(x) =  1/(1 + e^{-x})$\n",
    "* **learning_rate_init** (passo de aprendizado inicial)\n",
    "    * Apenas usado em otimizadores estocásticos.\n",
    "    * Este passo pode ser alterado durante o treinamento de acordo com o otimizador usado. Consulte a documentação para mais esclarecimentos.\n",
    "* **batch_size** (tamanho dos minibatches)\n",
    "    * Número de amostras que passam pela rede para cada ajuste de pesos.\n",
    "    * Só é usada para otimizadores estocásticos.\n",
    "* **max_iter** (número máximo de épocas de treinamento)\n",
    "* **early_stopping** (parada antecipada)\n",
    "    * Ao definir esta variável como *True*, o processo de ajuste de pesos estará sujeito a terminar de forma antecipada, caso o score no **conjunto de validação** não melhore por pelo menos **tol** (valor definido para a tolerância) em duas **épocas de treinamento** consecutivas. \n",
    "    * Esta variável melhora a rapidez do processamento da rede para otmizadores estocásticos.\n",
    "    * Definir essa variável como *True* não é eficaz se o solver for definido como lbfgs.\n",
    "* **validation_fraction**\n",
    "    * Define um percentual do conjunto de treino que será usado ao final de cada **época de treinamento** para medir a performance da rede, caso **early_stopping** seja definido como *True*.\n",
    "    * Este subconjunto, chamado de **conjunto de validação**, não é usado diretamente no ajuste de pesos, representando um conjunto de testes provisório.\n",
    "* **random_state** (estado aleatório)\n",
    "    * Semente de aleatoriedade que controla todos os processos aletaórios usados na criação da rede.\n",
    "    * Definir esta variável não é essencial, mas garante a reprodutibilidade dos resultados obtidos para um determinado conjunto de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a classe que permite criar percéptrons de múltiplas camadas para tarefas de classificação\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Criando uma rede neural com 3 camadas escondidas\n",
    "classifier_sk=MLPClassifier(random_state=0, solver='lbfgs', hidden_layer_sizes=[100,50,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os objetos já instanciados, a função *fit*, presente em ambas as classes, realiza todo o processo de apendizado, estando as redes, após a aplicação deste função, prontas para serem testadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando os pesos da rede ao conjunto de treino\n",
    "classifier_sk.fit(x_train,y_train)\n",
    "\n",
    "# Aplicando a rede já treinada ao conjunto de testes\n",
    "# Observe aue a veriável independente não é passada como parâmetro\n",
    "y_pred=classifier_sk.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos resultados\n",
    "Para avaliar os resultados de um problema de classificação, usaremos uma ferramenta chamada **matriz de confusão**. Esta matriz é útil por mostrar não somente a precisão de cada modelo, mas também os tipos de erro cometido, sendo possível identificar, por exemplo, se a rede tende a classificar os exemplos mais em uma classe do que nas outras.\n",
    "Observe a figura abaixo: <img src=\"confusionMatrix.png\" style=\"width: 400px\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a função que permite avaliar a matriz de confusao\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Revertendo o OneHotEncoder (para a criação da matriz de confusao) com a\n",
    "## multiplicacao da matriz de previsões pelo vetor [0,1,2]\n",
    "y_pred_rev=np.matmul(y_pred,[0,1,2])\n",
    "y_test_rev=np.matmul(y_test,[0,1,2])\n",
    "\n",
    "# Criando a matriz de confusao\n",
    "cm = confusion_matrix(y_test_rev, y_pred_rev)\n",
    "\n",
    "# Resultado\n",
    "print('Matriz de Confusão\\n'+str(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "Faça uma rede com o **solver sgd** e com parada antecipada. Defina o **learning_rate_init** como 1 e veja a matriz de confusão da máquina. Por que isso ocorreu?\n",
    "\n",
    "### Exercício 2\n",
    "Teste outras topologias para a rede. Qual é o número mínimo de neurônios a conseguir um resultado 100%? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando keras + tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializando a rede neural\n",
    "* A criação da rede neural pela biblioteca keras, que usa o tensorflow como backend, tem a vantagem de permitir um ajuste mais fino dos parâmetros do que a sklearn, mantendo, todavia, um nível baixo de complexidade.\n",
    "* Esta biblioteca permite que se ajuste os detalhes de cada camada individualmente, sendo a rede definida como uma **sequência de camadas**. Por este motivo, a rede abaixo deverá ser inicializada como um objeto da classe *Sequential*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importando a biblioteca Keras\n",
    "import keras\n",
    "\n",
    "# Importando a classe usada para inicializar a rede neural\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Inicializando a rede neural\n",
    "classifier_kt = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando as camadas da rede\n",
    "* Cada camada tem como parâmetros o número de entradas (**input_dim**), o número de saídas (**output_dim**), os pesos iniciais (**init**) e a função de ativação da camada (**activation**).\n",
    "* O parâmetro **input_dim** só necessita ser explicitado na primeira camada, na qual representa o número de inputs. Nas demais, fica subentendido que o número de entradas é igual ao número de saídas da camada anterior.\n",
    "* O **output_dim** é igual ao número de neurônios de cada camada. Na cadama de saída, este parâmetro deve ser igual à quantidade de outputs da rede ou ao número de dummy variables, caso se esteja lidando com uma variável que usou o *OneHotEncoder*.\n",
    "* Para a camada de saída num problema de classificação, a função de ativação recomendada é *softmax*, caso se esteja lidando com dummy variables, ou *sigmoid* caso contrário.\n",
    "    * Ambas as funções não retornam valores binários, mas probabilidades, portanto precisam ser convertidas em números binários ao final do processo.\n",
    "    * A diferença fundamental entre elas reside no fato de que a *sigmoid* analisa as variáveis individualmente, permitindo que mais de um valor seja igual a 1 ou que todos sejam iguais a 0.\n",
    "* É desejável que os pesos sejam inicializados como números aleatórios pequenos. Portanto, aqui se usará um gerador de números aleatórios com uma distribuição uniforme entre -0,5 e 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a classe usada para criar as camadas da rede\n",
    "from keras.layers import Dense \n",
    "\n",
    "# Criando a variável que inicializará os pesos\n",
    "init=keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=0)\n",
    "\n",
    "# Criando a camada de entrada e a primeira camada escondida da rede\n",
    "classifier_kt.add(Dense(output_dim=100,init=init,activation='relu', input_dim=6))\n",
    "\n",
    "# Criando a segunda camada escondida da rede\n",
    "classifier_kt.add(Dense(output_dim=50,init=init,activation='relu'))\n",
    "\n",
    "# Criando a terceira camada escondida da rede\n",
    "classifier_kt.add(Dense(output_dim=25,init=init,activation='relu'))\n",
    "\n",
    "# Criando a camada de saida\n",
    "classifier_kt.add(Dense(output_dim=3,init=init,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando a rede neural ao conjunto de treino\n",
    "* Com o formato da rede já definido, agora é necessário definir os parâmetros que serão usados no ajuste dos pesos:\n",
    "    * **optimizer**\n",
    "        * Método de otimização usado.\n",
    "        * Tem função idêntica ao parâmetro *solver* no MLPClassifier.\n",
    "        * <a href=\"https://keras.io/optimizers/\">Lista dos métodos disponíveis</a>.\n",
    "    * **loss**\n",
    "        * Função objetivo da otimização.\n",
    "        * A mais comum para problemas de classificação binária é a *binary_crossentropy*.\n",
    "        * Já para problemas com mais de 2 categorias, a mais recomendada é a função *categorical_crossentropy*\n",
    "        * O MLPClassifier não possui parâmetro ajustável equivalente.\n",
    "* Além desses dois parâmetros obrigatórios, também há o parâmetro **metrics**, que é uma função usada para avaliar a performance do modelo. Ela se diferencia da **loss** por não ser usada no ajuste dos pesos, sendo apenas uma métrica adicional para a vizualização do programador durante o processo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a rede neural\n",
    "classifier_kt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustando a rede neural ao conjunto de treino\n",
    "classifier_kt.fit(x_train,y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a previsão de y\n",
    "y_pred=classifier_kt.predict(x_test)\n",
    "# Transformando os valores previstos em binário\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a função que permite avaliar a matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Revertendo o OneHotEncoder (para a criação da matriz de confusão) com a\n",
    "## multiplicação da matriz de previsões pelo vetor [0,1,2]\n",
    "y_pred_rev=np.matmul(y_pred,[0,1,2])\n",
    "y_test_rev=np.matmul(y_test,[0,1,2])\n",
    "\n",
    "# Criando a matriz de confusão\n",
    "cm = confusion_matrix(y_test_rev, y_pred_rev)\n",
    "\n",
    "# Resultado\n",
    "print('Matriz de Confusão\\n'+str(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3\n",
    "Usando a rede criada com o keras, varie os parâmetros **epochs** e **batch_size** e veja o impacto dos mesmos no desempenho da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - Regressão\n",
    "<font color='blue'>Problemas de regressão são aqueles cujo desafio é prever o valor de uma variável dependente não categórica, tal como a variável **throughput** deste dataset, que pode assumir qualquer valor no intervalo de de 0 a 4,1 Mbps. Nesta etapa do HandsOn, você deverá criar uma rede neural usando as bibliotecas sklearn, keras e tensorflow para tentar achar o valor desta variável.</font>\n",
    "\n",
    "Obs.: Antes de criar os regressores, execute o código criado no exercício 1 da parte 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output scaling\n",
    "* No problema anterior, a padronização da escala do output não foi mencionada, pois o mesmo já se encontrava em formato binário. Apesar de não obrigatória, essa padronização tende a melhorar a performance da rede quando o intervalo de valores possivelmente assumidos por y é muito extenso.\n",
    "* Todavia, quando saber o valor do output na escala original é necessário, **a padronização deve ser revertida após a saída da rede neural**.\n",
    "* Observe que apenas o y_train é passado à máquina, portanto y_test não precisa ser padronizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.74434595]\n",
      " [3.25324784]\n",
      " [3.96798345]\n",
      " [3.79998007]]\n"
     ]
    }
   ],
   "source": [
    "# Criando um novo scaler\n",
    "fs_y=StandardScaler()\n",
    "\n",
    "# Modificando o formato do vetor de outputs\n",
    "y_train=np.array(y_train)\n",
    "y_train=y_train.reshape(-1, 1)\n",
    "\n",
    "y_test=np.array(y_test)\n",
    "y_test=y_test.reshape(-1, 1)\n",
    "\n",
    "# Transformando e ajustando apenas o conjunto de treinos\n",
    "y_train=fs_y.fit_transform(y_train)\n",
    "\n",
    "# Resultado nas 4 primeras linhas\n",
    "print(y_test[0:4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "Sabendo que os parâmetros do <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\">**MLPRegressor**</a> são idênticos aos do MLPClassifier, crie e treine uma rede neural para encontrar o **throughput** com esta classe. Use os parâmetros que desejar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos resultados\n",
    "Para avaliar os resultados dos problemas de regressão, usaremos a função de erro médio quadrático, cuja fórmula encontra-se abaixo:\n",
    "\n",
    "####  <center>  $ E_{mse} = \\sum_{i=1}^{N}\\frac{(y_{real}-y_{pred})}{N}$  </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a função que permite calcular o erro médio quadrático\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Invertendo o Standard Scaler\n",
    "y_pred=fs_y.inverse_transform(y_pred)\n",
    "\n",
    "# Calculando o erro médio quadrático\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Resultado\n",
    "print('Erro médio quadrático: '+str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "Usando a rede do exercício 1, desfaça a padronização do output e verifique o novo erro médio quadrático. Qual foi o impacto desta padronização no desempenho da rede?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Usando keras + tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assim como no sklearn, os parâmetros do keras + tensorflow também são os mesmos que os da tarefa de classificação. Há apenas algumas ressalvas a serem feitas:\n",
    "    * A **activation** da última camada deve ser adequada à natureza do problem. A mais comum para problemas de regressão é a *linear*, que permite que o output assuma qualquer valor, mas, por exemplo, se o seu output só possui valores positivos, a função *relu* lhe trará melhores resultados;\n",
    "    * A função **loss** mais usada para problemas de regressão é a *mean_squared_error* (erro médio quadrático).    \n",
    "\n",
    "\n",
    "### Exercício 3\n",
    "Crie e treine uma rede neural para encontrar o **throughput** dos usuários usando o keras. Avalie o desempenho da rede.\n",
    "\n",
    "Dica: Se lembre de ajustar o número de outputs na camada de saída. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
